---
apiVersion: v1
kind: Namespace
metadata:
  labels:
    name: tigera-mcm
  name: tigera-mcm
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tigera-guardian
  namespace: tigera-mcm
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: tigera-guardian-config
  namespace: tigera-mcm
data:
  # Server port for Guardian
  tigera-guardian.port: "9443"
  # Logging level
  tigera-guardian.log-level: "INFO"
  # Proxy Targets
  tigera-guardian.proxy-targets: '[
    {
      "path": "/api/",
      "url": "https://kubernetes.default",
      "tokenPath": "/var/run/secrets/kubernetes.io/serviceaccount/token",
      "caBundlePath": "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
    },
    {
      "path": "/apis/",
      "url": "https://kubernetes.default",
      "tokenPath": "/var/run/secrets/kubernetes.io/serviceaccount/token",
      "caBundlePath": "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
    },
    {
      "path": "/tigera-elasticsearch/",
      "url": "https://tigera-manager.tigera-manager.svc:9443"
    },
    {
      "path": "/compliance/",
      "url": "https://compliance.tigera-compliance.svc"
    }]'
  # This tells Guardian how to reach Voltron
  tigera-guardian.voltron-url: {{.VoltronURL}}
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: tigera-guardian
rules:
  - apiGroups: [""]
    resources: ["users", "groups", "serviceaccounts"]
    verbs: ["impersonate"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tigera-guardian
roleRef:
  kind: ClusterRole
  name: tigera-guardian
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: tigera-guardian
    namespace: tigera-mcm
---
apiVersion: v1
kind: Secret
metadata:
  name: tigera-guardian-certs
  namespace: tigera-mcm
type: Opaque
data:
  guardian.crt: {{.GuardianTLSCert | base64}}
  guardian.key: {{.GuardianTLSKey | base64}}
  # This validation token is signed by Voltron and contains metadata
  # about the Guardian's corresponding App Cluster (i.e. cluster ID,
  # display name, etc.)
  voltron.crt: {{.VoltronCert | base64}}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tigera-guardian
  namespace: tigera-mcm
  labels:
    k8s-app: tigera-guardian
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: tigera-guardian
  strategy:
    type: Recreate
  template:
    metadata:
      name: tigera-guardian
      namespace: tigera-mcm
      labels:
        k8s-app: tigera-guardian
      annotations:
        # Mark this pod as a critical add-on; when enabled,
        # the critical add-on scheduler reserves resources
        # for critical add-on pods so that they can be rescheduled
        # after a failure.  This annotation works in tandem
        # with the toleration below.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      serviceAccountName: tigera-guardian
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        # Allow this pod to be rescheduled while the node is in
        # "critical add-ons only" mode. This, along with the
        # annotation above marks this pod as a critical add-on.
        - key: CriticalAddonsOnly
          operator: Exists
      # Use the same pull secret as the rest of TSEE
      containers:
        - name: tigera-guardian
          image: {{VOLTRON_DOCKER_PUSH_REPO}}/tigera/guardian:{{VOLTRON_DOCKER_TAG}}
          imagePullPolicy: IfNotPresent
          env:
            - name: GUARDIAN_PORT
              valueFrom:
                configMapKeyRef:
                  name: tigera-guardian-config
                  key: tigera-guardian.port
            - name: GUARDIAN_LOGLEVEL
              valueFrom:
                configMapKeyRef:
                  name: tigera-guardian-config
                  key: tigera-guardian.log-level
            - name: GUARDIAN_PROXY_TARGETS
              valueFrom:
                configMapKeyRef:
                  name: tigera-guardian-config
                  key: tigera-guardian.proxy-targets
            - name: GUARDIAN_VOLTRON_URL
              valueFrom:
                configMapKeyRef:
                  name: tigera-guardian-config
                  key: tigera-guardian.voltron-url
          # QUESTION: Should we have resource limits defined?
          resources: {}
          volumeMounts:
            - mountPath: /certs/
              name: tigera-guardian-certs
              readOnly: true
          livenessProbe:
            httpGet:
              path: /health
              port: 9080
            initialDelaySeconds: 90
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 9080
            initialDelaySeconds: 10
            periodSeconds: 5
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
      volumes:
        - name: tigera-guardian-certs
          secret:
            secretName: tigera-guardian-certs
