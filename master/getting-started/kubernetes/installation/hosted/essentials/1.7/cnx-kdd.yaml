---
layout: null
---
# This manifest adds the additional CNX Manager components to a cluster
# that has already had the Calico part of CNX deployed.
# - It refers to the calico-config ConfigMap from that file, so if you are
#   not using the provided hosted Calico manifest you must update
#   references to that resource in this file.
# - Update the tigera-cnx-manager-config ConfigMap below before use.
# - Optionally update the cnx-apiserver-certs ConfigMap below before use to
#   enable TLS on the connection between the CNX API server and the
#   Kubernetes API server.
# - This manifest makes the CNX Manager web server available via a NodePort
#   serving on port 30003.  You may wish to update how this is exposed; do
#   so by editing the tigera-cnx-manager-access Service below.

# Update this ConfigMap with the Google login client id.
kind: ConfigMap
apiVersion: v1
metadata:
  name: tigera-cnx-manager-config
  namespace: kube-system
data:
  # Authentication type.  Must be set to "OIDC", "Basic" or "StaticToken".
  tigera.cnx-manager.authentication-type: "OIDC"
  # The OIDC authority.  Required if authentication-type is OIDC, ignored otherwise.
  tigera.cnx-manager.oidc-authority: "https://accounts.google.com"
  # The OIDC client id to use for OIDC login.  Kubelet must be configured accordingly.
  # Value is ignored if not using OIDC login.
  tigera.cnx-manager.oidc-client-id: "<fill-in-your-oauth-client-id-here>"
  # The location of the Kubernetes API.  This must be reachable from where the web interface
  # will be accessed from.  `kubectl proxy --port=8080` can be used; in this case set the
  # value of this field to "localhost:8080".
  tigera.cnx-manager.kubernetes-api: "127.0.0.1:6443"

---

# Optionally update this ConfigMap to enable TLS between the CNX API
# server and Kubernetes API server.
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: cnx-apiserver-certs
  namespace: kube-system
data:
  # Populate the following files with etcd TLS configuration if desired,
  # but leave blank if not using TLS for Kubernetes etcd.
  # This self-hosted install expects three files with the following names.  The values
  # should be base64 encoded strings of the entire contents of each file.
  #apiserver.key:
  #apiserver.crt:

---

# Optionally update this Service to change how CNX Manager is accessed.
# If using Google login, the URL for the web server must be configured
# as a redirect URI in the Google project.  If the web server will be
# accessed at https://<host>:<port>, add https://<host>:<port>/login/oidc/callback
# to the redirect URI list for the project.
apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: cnx-manager
  name: cnx-manager
  namespace: kube-system
spec:
  selector:
    k8s-app: cnx-manager
  ports:
    - port: 8080
      targetPort: 443
      nodePort: 30003
  type: NodePort

---

apiVersion: apiregistration.k8s.io/v1beta1
kind: APIService
metadata:
  name: v3.projectcalico.org
spec:
  insecureSkipTLSVerify: true
  group: projectcalico.org
  versionPriority: 200
  groupPriorityMinimum: 200
  service:
    name: api
    namespace: kube-system
  version: v3

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: calico:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: cnx-apiserver
  namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: calico-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: cnx-apiserver
  namespace: kube-system

---

kind: ServiceAccount
apiVersion: v1
metadata:
  name: cnx-apiserver
  namespace: kube-system

---

kind: ServiceAccount
apiVersion: v1
metadata:
  name: cnx-manager
  namespace: kube-system

---

# Give cnx-apiserver ServiceAccount same level of access
# as calico-node ServiceAccount. This is needed for
# accessing various CRDs and namespaces.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: cnx-apiserver-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: cnx-apiserver
  namespace: kube-system

---

apiVersion: v1
kind: Service
metadata:
  name: api
  namespace: kube-system
spec:
  ports:
  - port: 443
    protocol: TCP
    targetPort: 5443
  selector:
    apiserver: "true"

---

apiVersion: v1
kind: ReplicationController
metadata:
  name: cnx-apiserver
  namespace: kube-system
  labels:
    apiserver: "true"
spec:
  replicas: 1
  selector:
    apiserver: "true"
  template:
    metadata:
      labels:
        apiserver: "true"
    spec:
      serviceAccountName: cnx-apiserver
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      containers:
      - name: cnx-apiserver
        image: {{site.imageNames["cnxApiserver"]}}:{{site.data.versions[page.version].first.components["cnx-apiserver"].version}}
        args:
        - "--secure-port=5443"
        env:
          - name: DATASTORE_TYPE
            value: "kubernetes"
        volumeMounts:
          - mountPath: /code/apiserver.local.config/certificates
            name: apiserver-certs
      volumes:
        - name: apiserver-certs
          secret:
            secretName: cnx-apiserver-certs

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: cnx-manager
  namespace: kube-system
  labels:
    k8s-app: cnx-manager
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      name: cnx-manager
      namespace: kube-system
      labels:
        k8s-app: cnx-manager
      annotations:
        # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
        # reserves resources for critical add-on pods so that they can be rescheduled after
        # a failure.  This annotation works in tandem with the toleration below.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      serviceAccountName: cnx-manager
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      # This, along with the annotation above marks this pod as a critical add-on.
      - key: CriticalAddonsOnly
        operator: Exists
      containers:
      - name: cnx-manager
        image: {{site.imageNames["cnxManager"]}}:{{site.data.versions[page.version].first.components["cnx-manager"].version}}
        env:
          - name: CNX_WEB_AUTHENTICATION_TYPE
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.authentication-type
          - name: CNX_WEB_OIDC_AUTHORITY
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.oidc-authority
          - name: CNX_WEB_OIDC_CLIENT_ID
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.oidc-client-id
          - name: CNX_WEB_K8S_API
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.kubernetes-api
        volumeMounts:
        - mountPath: /etc/cnx-manager-web-tls
          name: cnx-manager-tls
      volumes:
      - name: cnx-manager-tls
        secret:
          secretName: cnx-manager-tls
