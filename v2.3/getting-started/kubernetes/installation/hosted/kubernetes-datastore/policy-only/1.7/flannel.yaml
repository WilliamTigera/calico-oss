# This file installs flanneld in a way that is compatible with our policy-only
# manifest.  I.e. it installs flanneld without its CNI plugin.

kind: ConfigMap
apiVersion: v1
metadata:
  name: flannel-config
  namespace: kube-system
data:
  # The interface used by flannel for host <-> host communication.
  # If left blank, then the interface is chosen using the node's
  # default route.
  flannel_iface: ""

  # Whether or not to masquerade traffic to destinations not within
  # the pod network.
  masquerade: "true"

  # Flannel network configuration. Mounted into the flannel container.
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "host-gw"
      }
    }

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - patch

---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-system

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: flannel
  namespace: kube-system

---

# This manifest installs flanneld on each host but it does not install
# the flannel CNI plugin (since we want to use our own instead).
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: flannel
  namespace: kube-system
  labels:
    k8s-app: flannel
spec:
  selector:
    matchLabels:
      k8s-app: flannel
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: flannel
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
      # Make sure flannel gets scheduled on all nodes.
      - effect: NoSchedule
        operator: Exists
      # Mark the pod as a critical add-on for rescheduling.
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoExecute
        operator: Exists
      serviceAccountName: flannel
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      containers:
      # This container runs flannel using the kube-subnet-mgr backend
      # for allocating subnets.
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.9.1
        command: [ "/opt/bin/flanneld", "--ip-masq", "--kube-subnet-mgr" ]
        securityContext:
          privileged: true
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: FLANNELD_IFACE
          valueFrom:
            configMapKeyRef:
              name: flannel-config
              key: flannel_iface
        - name: FLANNELD_IP_MASQ
          valueFrom:
            configMapKeyRef:
              name: flannel-config
              key: masquerade
        volumeMounts:
        - name: run
          mountPath: /run
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
      - name: run
        hostPath:
          path: /run
      - name: flannel-cfg
        configMap:
          name: flannel-config
