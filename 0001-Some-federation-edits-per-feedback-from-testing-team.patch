From 4cbf173f4457a9b5a3371c9a5817c2213ef326b4 Mon Sep 17 00:00:00 2001
From: emanic <eanicich@yahoo.com>
Date: Thu, 27 Sep 2018 16:13:05 -0700
Subject: [PATCH] Some federation edits per feedback from testing team

---
 _data/master/navbars/usage.yml                 |  2 +-
 _includes/master/gs-next-steps.md              |  2 +-
 master/usage/federation/aws.md                 |  6 +--
 master/usage/federation/configure-rcc.md       | 54 +++++++++++---------
 master/usage/federation/index.md               | 24 +++------
 master/usage/federation/kubeconfig.md          | 14 ++---
 master/usage/federation/services-controller.md | 14 ++---
 7 files changed, 52 insertions(+), 64 deletions(-)

diff --git a/_data/master/navbars/usage.yml b/_data/master/navbars/usage.yml
index ba8d5f86..6def7934 100644
--- a/_data/master/navbars/usage.yml
+++ b/_data/master/navbars/usage.yml
@@ -82,7 +82,7 @@ toc:
     path: /usage/federation/
   - title: Creating kubeconfig files
     path: /usage/federation/kubeconfig
-  - title: Configuring remote clusters
+  - title: Configuring access to remote clusters
     path: /usage/federation/configure-rcc
   - title: Configuring federated services
     path: /usage/federation/services-controller
diff --git a/_includes/master/gs-next-steps.md b/_includes/master/gs-next-steps.md
index 22f766c8..2cff58aa 100644
--- a/_includes/master/gs-next-steps.md
+++ b/_includes/master/gs-next-steps.md
@@ -11,5 +11,5 @@ For more detailed documentation on {{site.prodname}} features, see here:
 - [Configuring Alertmanager]({{site.baseurl}}/{{page.version}}/usage/configuration/alertmanager)
 - [Configuring Audit Logging]({{site.baseurl}}/{{page.version}}/usage/logs/elastic/k8s-audit)
 - [Configuring RBAC]({{site.baseurl}}/{{page.version}}/reference/cnx/rbac-tiered-policies)
-- [Configuring remote clusters]({{site.baseurl}}/{{page.version}}/usage/federation/configure-rcc) (federation only)
+- [Configuring access to remote clusters]({{site.baseurl}}/{{page.version}}/usage/federation/configure-rcc) (federation only)
 - [Configuring federated services]({{site.baseurl}}/{{page.version}}/usage/federation/services-controller) (federation only)
diff --git a/master/usage/federation/aws.md b/master/usage/federation/aws.md
index 8a62b565..ff524d3a 100644
--- a/master/usage/federation/aws.md
+++ b/master/usage/federation/aws.md
@@ -6,7 +6,7 @@ title: Example AWS configuration

 This section gives a brief overview of a example AWS cluster peered with an on-premise cluster running on physical hardware.
 Both clusters are running {{site.prodname}}. The clusters have federated identity configured, with each cluster
-referencing the other using the Remote Cluster Configuration resource. See the [Configuring remote clusters](./configure-rcc) guide for
+referencing the other using the Remote Cluster Configuration resource. See [Configuring access to remote clusters](./configure-rcc) for
 more details.

 The diagram below captures the main configuration details for this particular set up, which may be adapted for your specific
@@ -15,7 +15,7 @@ requirements. This is purely a guide for setting up one specific configuration.
 ![A diagram showing the key configuration requirements setting up an AWS cluster (using AWS VPN CNI) peering
 with an on-premise cluster.](/images/federation/aws-rcc.svg)

-#### AWS configuration:
+## AWS configuration
 - A VPC CIDR is chosen that does not overlap with the on-premise IP ranges.
 - There are 4 subnets within the VPC, split across two AZs (for availability) such that each AZ has a public and private subnet. In this
   particular example, the split of responsibility is:
@@ -58,7 +58,7 @@ spec:
   type: LoadBalancer
 ```

-#### On-premise configuration
+## On-premise configuration
 In this example the cluster is installed on real hardware and node and pod IPs are routable,
 using an edge VPN router to peer with the AWS cluster.

diff --git a/master/usage/federation/configure-rcc.md b/master/usage/federation/configure-rcc.md
index ee849eb2..6f726dbe 100644
--- a/master/usage/federation/configure-rcc.md
+++ b/master/usage/federation/configure-rcc.md
@@ -1,22 +1,28 @@
 ---
-title: Configuring remote clusters
+title: Configuring access to remote clusters
 ---

-## About configuring remote clusters
+## About configuring access to remote clusters

-To create policies that reference endpoints across multiple clusters, you must allow the clusters to obtain endpoint information from
-each other by [adding Remote Cluster Configuration resources](#adding-a-remote-cluster-configuration-resource).
+To allow a local cluster to pull endpoint data from a remote cluster, you must add a Remote Cluster
+Configuration resource to the local cluster.

-For example, if you have two clusters and you want to create policies that reference endpoints on both, you would:
+For example, let's imagine that you want to federate three clusters named `cluster-a`, `cluster-b`,
+and `cluster-c`.

-- Add a Remote Cluster Configuration resource to cluster A that allows it to obtain endpoint information from cluster B.
-- Add a Remote Cluster Configuration resource to cluster B that allows it to obtain endpoint information from cluster A.
+After installing {{site.prodname}} on each of the clusters:

-You can add multiple Remote Cluster Configuration resources to a cluster, allowing it to obtain endpoint information
-from more than one cluster.
+- Add two Remote Cluster Configuration resources to `cluster-a`: one for `cluster-b` and another
+  for `cluster-c`.
+
+- Add two Remote Cluster Configuration resources to `cluster-b`: one for `cluster-a` and another
+  for `cluster-c`.
+
+- Add two Remote Cluster Configuration resources to `cluster-c`: one for `cluster-a` and another
+  for `cluster-b`.

 In addition to adding the necessary Remote Cluster Configuration resources, you may need to
-[modify your IP Pool configuration](#configuring-ip-pool-resources-for-federated-endpoint-identity).
+[modify the local cluster's IP pool configuration](#configuring-ip-pool-resources).

 ## Adding a Remote Cluster Configuration resource

@@ -30,8 +36,8 @@ cluster's datastore type.

 ### About adding a Remote Cluster Configuration resource

-Each instance of the [Remote Cluster Configuration](/{{page.version}}/reference/calicoctl/resources/remoteclusterconfiguration) resource represents a single remote cluster from which the local cluster can retrieve endpoint
-information. The local cluster can talk to multiple remote clusters.
+Each instance of the [Remote Cluster Configuration](/{{page.version}}/reference/calicoctl/resources/remoteclusterconfiguration)
+resource represents a single remote cluster from which the local cluster can retrieve endpoint information.

 The resource definition varies according to your datastore type. Refer to the section that corresponds to your datastore
 type for instructions.
@@ -40,15 +46,15 @@ type for instructions.

 ### Adding a Remote Cluster Configuration resource with the etcd datastore

-If the remote cluster uses etcd as the {{site.prodname}} datastore, set the `datastoreType` in the RemoteClusterConfiguration
-to `etcdv3` and populate the `etcd*` fields. You must also fill in either the `kubeconfig` or the `k8s*` fields.
+If the remote cluster uses etcd as the {{site.prodname}} datastore, set the `datastoreType` in the Remote Cluster Configuration
+resource to `etcdv3` and populate the `etcd*` fields. You must also fill in either the `kubeconfig` or the `k8s*` fields.

 As long as you followed the installation instructions, the files in the
 [`tigera-federation-remotecluster` secret created during installation](/{{page.version}}/getting-started/kubernetes/installation/calico#installing-with-federation-using-etcd)
-will appear in the Typha pod in the `/etc/tigera-federation-remotecluster` directory and the [RemoteClusterConfiguration](/{{page.version}}/reference/calicoctl/resources/remoteclusterconfiguration)
-can reference the files using this path.
+will appear in the Typha pod in the `/etc/tigera-federation-remotecluster` directory and
+the Remote Cluster Configuration resource can reference the files using this path.

-An example Remote Configuration Resource for etcd follows.
+An example Remote Cluster Configuration resource for etcd follows.

 ```yaml
 apiVersion: projectcalico.org/v3
@@ -65,7 +71,7 @@ spec:
 ### Remote Cluster Configuration resource with the Kubernetes API datastore

 If the remote cluster uses the Kubernetes API datastore for {{site.prodname}} data,
-set the `datastoreType` in the `RemoteClusterConfiguration`
+set the `datastoreType` in the Remote Cluster Configuration resource
 to `kubernetes` and populate the `kubeconfig` or `k8s*` fields.

 As long as you followed the installation instructions, the files in the
@@ -73,7 +79,7 @@ As long as you followed the installation instructions, the files in the
 will appear in the Typha pod in the `/etc/tigera-federation-remotecluster` directory and the [RemoteClusterConfiguration](/{{page.version}}/reference/calicoctl/resources/remoteclusterconfiguration)
 can reference the files using this path.

-An example Remote Configuration Resource for the Kubernetes API datastore follows.
+An example Remote Cluster Configuration resource for the Kubernetes API datastore follows.

 ```yaml
 apiVersion: projectcalico.org/v3
@@ -85,13 +91,13 @@ spec:
   kubeconfig: /etc/tigera-federation-remotecluster/kubeconfig-rem-cluster-n
 ```

-## Configuring IP Pool resources for federated endpoint identity
+## Configuring IP pool resources

-If your local cluster has NATOutgoing configured on your IP Pools, it is necessary to configure IP Pools covering the IP ranges
-of your remote clusters. This ensures outgoing NAT is not performed on packets bound for the remote clusters. These additional
-IP Pools should have `disabled` set to `true` to ensure the pools are not used for IP assignment on the local cluster.
+If your local cluster has `NATOutgoing` configured on your IP pools, you must to configure IP pools covering the IP ranges
+of your remote clusters. This ensures that outgoing NAT is not performed on packets bound for the remote clusters. These additional
+IP pools should have `disabled` set to `true` to ensure the pools are not used for IP assignment on the local cluster.

-The IP Pool CIDR used for pod IP allocation should not overlap with any of the IP ranges used by the pods and nodes of any
+The IP pool CIDR used for pod IP allocation should not overlap with any of the IP ranges used by the pods and nodes of any
 other federated cluster.

 For example, you may configure the following on your local cluster, referring to the `IPPool` on a remote cluster:
diff --git a/master/usage/federation/index.md b/master/usage/federation/index.md
index 883648d3..af06caf7 100644
--- a/master/usage/federation/index.md
+++ b/master/usage/federation/index.md
@@ -14,13 +14,11 @@ Federation allows you to:

 When discussing federation, we use the following terms:

-- **Local clusters** can retrieve endpoint data from remote clusters and are equipped with an installation
-  of {{site.prodname}}.
+- **Local clusters** retrieve endpoint data from remote clusters.

-- **Remote clusters** send endpoint data to local clusters and do not require {{site.prodname}}
-  to be installed.
+- **Remote clusters** allow local clusters to retrieve endpoint data.

-Clusters can act both as local and remote clusters.
+Each cluster in the federation acts as both a local and remote cluster.

 ## Federated endpoint identity

@@ -48,7 +46,7 @@ resource. A Remote Cluster Configuration resource should be added for each remot
 Similar configuration should be applied on the remote clusters if you require Federated Endpoint Identity on those
 clusters.

-Refer to [Configuring remote clusters](./configure-rcc) for more information.
+Refer to [Configuring local clusters](./configure-rcc) for more information.

 ## Federated Services

@@ -58,11 +56,11 @@ then Kubernetes will manage that service, populating the service endpoints from

 Tigera Federated Services Controller is used alongside Federated Endpoint
 Identity to provide discovery of remote pods. It extends the standard Kubernetes service and endpoints functionality to
-provide federation of [Kubernetes endpoints]() across all of the clusters.
+provide federation of [Kubernetes endpoints](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#endpoints-v1-core) across all of the clusters.

 Configuration for this feature is also through the [Remote Cluster Configuration](/{{page.version}}/reference/calicoctl/resources/remoteclusterconfiguration)
-resource. In addition, a
-[service annotation](/{{page.version}}/usage/federation/services-controller) is used to configure a federated service.
+resource. In addition, a [service annotation](/{{page.version}}/usage/federation/services-controller) is used to configure
+a federated service.

 > **Note**: The controller always uses the pod IP for the service endpoints even for pods in remote clusters,
 > thus if a pod on the local cluster uses a federated service to access a pod in a remote cluster, source and
@@ -78,11 +76,3 @@ in the Remote Cluster Configuration resources are also accessible to `calicoq`,
 is the simplest way to ensure it has access to the correct configuration.

 At this time, neither the {{site.prodname}} Manager nor `calicoctl` can be used to view endpoints from remote clusters.
-
-## More information and next steps
-
-To learn more and configure federation, see the following:
-- [Configuring remote clusters](/{{page.version}}/usage/federation/configure-rcc)
-- [Configuring federated services](/{{page.version}}/usage/federation/services-controller)
-- [Example AWS configuration](/{{page.version}}/usage/federation/aws)
-- [Installing and configuring calicoq as a pod](/{{page.version}}/usage/calicoq/#installing-calicoq-as-a-kubernetes-pod)
diff --git a/master/usage/federation/kubeconfig.md b/master/usage/federation/kubeconfig.md
index 51cde83f..880001ad 100644
--- a/master/usage/federation/kubeconfig.md
+++ b/master/usage/federation/kubeconfig.md
@@ -2,18 +2,11 @@
 title: Creating kubeconfig files
 ---

-The following procedure describes how to access a [remote cluster](index#terminology) create a service
-account with a minimal set of permissions, and generate a `kubeconfig` file that uses the service account.
-
-When installing {{site.prodname}} on a [local cluster](index#terminology), you must provision the necessary
-`kubeconfig` files to allow it to retrieve endpoint data from the remote cluster.
-
-Complete the following steps on each cluster that needs to share its endpoint data.
+Before installing {{site.prodname}}, you must complete the following steps on each cluster in the federation.

 1. Access the cluster using a `kubeconfig` with administrative privileges.

-1. If RBAC is enabled, apply the manifest that matches the remote cluster's datastore type. The manifest
-   creates the minimum set of permissions that the local cluster needs to retrieve the endpoint data for federation.
+1. If RBAC is enabled, apply the manifest that matches the cluster's datastore type.

    - **Kubernetes API datastore**
      ```bash
@@ -27,8 +20,7 @@ Complete the following steps on each cluster that needs to share its endpoint da
      {{site.url}}/{{page.version}}/getting-started/kubernetes/installation/federation-rem-rbac-etcd.yaml
      ```

-1. Apply the following manifest to create a service account called `tigera-federation-remote-cluster`
-   on the remote cluster. The local cluster will use this account to access the remote cluster.
+1. Apply the following manifest to create a service account called `tigera-federation-remote-cluster`.

    ```bash
    kubectl apply -f \
diff --git a/master/usage/federation/services-controller.md b/master/usage/federation/services-controller.md
index 8d93ae13..197d4c32 100644
--- a/master/usage/federation/services-controller.md
+++ b/master/usage/federation/services-controller.md
@@ -15,7 +15,7 @@ policy to be applied between the clusters.
 The Federated Services Controller accesses service and endpoints data in the remote clusters directly through the
 Kubernetes API. This means that if the remote cluster is using etcd for the {{site.prodname}} datastore, it is necessary to configure
 both etcd access details and Kubernetes API datastore access details in the same Remote Cluster Configuration resource. See
-[Configuring a Remote Cluster Configuration resource](./configure-rcc) for more details.
+[Configuring access to remote clusters](./configure-rcc) for more details.

 ## Configuring a federated service

@@ -27,7 +27,7 @@ The following configuration options are valid through the annotations:

 | Annotation | Description |
 | --- | --- |
-| federation.tigera.io/serviceSelector | {::nomarkdown}<p>This option is used to specify which services are used in the federated service. This field must be specified for the service to be federated. If the value is incorrectly specified, the service will not be federated and endpoint data will be removed from the service. Warning logs will be output in the controller indicating any issues processing this value.</p><p>The format is a standard {{site.prodname}} selector (i.e. the same as {{site.prodname}} policy resources) and selects services based on their labels.</p><p>Only services in the same namespace as the federated service will be included. This implies namespace names across clusters are linked (this is a basic premise of Federated Endpoint Identity).</p>{:/} |
+| `federation.tigera.io/serviceSelector` | {::nomarkdown}<p>This option is used to specify which services are used in the federated service. This field must be specified for the service to be federated. If the value is incorrectly specified, the service will not be federated and endpoint data will be removed from the service. Warning logs will be output in the controller indicating any issues processing this value.</p><p>The format is a standard {{site.prodname}} selector (i.e. the same as {{site.prodname}} policy resources) and selects services based on their labels.</p><p>Only services in the same namespace as the federated service will be included. This implies namespace names across clusters are linked (this is a basic premise of Federated Endpoint Identity).</p>{:/} |

 The Federated Services Controller uses the serviceSelector annotation to select the backing services in the same
 namespace whose labels match the specified selector. Services are selected from the local and remote clusters.
@@ -40,14 +40,14 @@ when viewing the service through `kubectl.`

 | Label | Description |
 | --- | --- |
-| federation.tigera.io/remoteClusterName | {::nomarkdown}<p>The label is added to all of the remote services, and the value corresponds to the name of the Remote Cluster Configuration that specifies the remote cluster. For services in the local cluster, this label is not added.</p><p>You may wish to use this label if you need to restrict which clusters the services are selected from.</p>{:/} |
+| `federation.tigera.io/remoteClusterName` | {::nomarkdown}<p>The label is added to all of the remote services, and the value corresponds to the name of the Remote Cluster Configuration that specifies the remote cluster. For services in the local cluster, this label is not added.</p><p>You may wish to use this label if you need to restrict which clusters the services are selected from.</p>{:/} |

 The controller monitors any changes to the endpoints for the backings services and maintains the set of endpoints for
 each locally federated service. The controller makes no configuration changes to any remote cluster.

-The endpoints data configured in the federated service is slightly modified from the original data of the backing service:
--  For backing services on remote clusters, the `targetRef.name` field in the federated service will be updated to the
-   form `<Remote Cluster Configuration name>/<original name>`.
+The endpoints data configured in the federated service is slightly modified from the original data of the backing service.
+For backing services on remote clusters, the `targetRef.name` field in the federated service will be updated to the
+form `<Remote Cluster Configuration name>/<original name>`.

 > **Please note**:
 > -  If a spec.Selector is also specified, the Federated Services Controller will not federate the service.
@@ -100,7 +100,7 @@ As an operator, the expected flow of configuration would be as follows:
 >    *services* across the federated set of clusters. This is a {{site.prodname}} style selector.
 {: .alert .alert-success}

-### Example
+## Example

 For example, suppose both your local cluster and a remote cluster have the following service defined:

--
2.17.0
